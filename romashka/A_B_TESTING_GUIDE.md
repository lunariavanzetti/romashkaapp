# Complete A/B Testing & Customer Testing Guide

## ğŸ¯ Understanding A/B Testing in ROMASHKA

### What A/B Testing Actually Tests

A/B testing in ROMASHKA tests **two different AI personality configurations** on real customer conversations to determine which performs better.

**Example Scenario (Sarah's SaaS Company):**
- **Variant A (Formal)**: Professional, structured responses
  - Friendliness: 60%, Professionalism: 90%
  - Greeting: "How may I assist you today?"
  
- **Variant B (Friendly)**: Casual, warm responses  
  - Friendliness: 95%, Professionalism: 70%
  - Greeting: "Hey! I'd love to help you out ğŸ˜Š"

### What Gets Measured

The system tracks real metrics from customer interactions:
- **Response Time**: How fast each variant responds
- **Satisfaction Score**: Customer feedback (1-5 stars)
- **Escalation Rate**: How often customers need human help
- **Conversion Rate**: How often customers complete desired actions
- **Statistical Significance**: P-values and confidence intervals

## ğŸ§ª How to Test A/B Testing (Step by Step)

### Method 1: Playground Testing (Quick Demo)

1. **Go to Playground â†’ A/B Testing tab**
2. **Create A/B Test**: Click "Create A/B Test"
   - This creates database records for both personality variants
3. **Start Test**: Click "Start Test" 
   - Generates 100 sample conversations with realistic data
   - Variant B is designed to perform ~23% better than Variant A
4. **View Results**: Click "View Results"
   - Shows detailed statistical analysis
   - Declares winner with improvement percentage
   - Provides business recommendations

### Method 2: Real Customer Testing (Production)

#### Setup Required:
1. **Widget Configuration**: Customer embeds chat widget on their website
2. **Knowledge Base**: Upload website content via URL Scanner
3. **Multi-Channel Setup**: Configure WhatsApp/Instagram if needed
4. **A/B Test Creation**: Define two personality variants

#### Real Customer Flow:
```
Customer visits website â†’ Chat widget loads â†’ 
System assigns Variant A or B â†’ Customer chats â†’ 
Metrics recorded â†’ Results analyzed
```

## ğŸ”§ Fixing OpenAI API Connection Error

The "Connection error" in playground testing happens because OpenAI API calls from browser can be blocked. Here's the fix:

### Issue Resolution:

```typescript
// Current issue: Browser-based OpenAI calls
this.openai = new OpenAI({
  apiKey: import.meta.env.VITE_OPENAI_API_KEY,
  dangerouslyAllowBrowser: true  // âš ï¸ Security risk
});
```

### Solutions:

#### Option 1: Server Proxy (Recommended)
Create a backend endpoint that handles OpenAI calls:
```
Frontend â†’ Your Backend API â†’ OpenAI API â†’ Response
```

#### Option 2: Mock Responses (Quick Fix)
For testing purposes, use realistic mock responses:
```typescript
// Fallback when OpenAI fails
if (apiError) {
  return generateMockResponse(testMessage, botConfig);
}
```

## ğŸŒŸ Multi-Channel Hub Testing

### WhatsApp/Instagram Setup:

Yes, customers need to set up webhooks and access tokens just like Lyro AI:

1. **WhatsApp Business API**:
   - Phone Number ID: `738957062628625`
   - Access Token: From Meta Business
   - Webhook URL: `https://romashkaai.vercel.app/webhook/whatsapp`
   - Verify Token: Custom secret

2. **Instagram Messaging**:
   - Instagram Business Account
   - Connected Facebook Page
   - Webhook for DM handling

3. **Testing Flow**:
   ```
   Customer texts WhatsApp â†’ Webhook receives â†’ 
   A/B test assigns variant â†’ AI responds â†’ 
   Metrics tracked â†’ Results analyzed
   ```

## ğŸ“Š Real A/B Testing Example

### Sarah's SaaS Company Results:
```
Variant A (Formal):
- Response Time: 847ms avg
- Satisfaction: 3.8/5 avg  
- Conversion Rate: 15.2%
- Escalation Rate: 24.5%

Variant B (Friendly):
- Response Time: 623ms avg
- Satisfaction: 4.2/5 avg
- Conversion Rate: 23.1% 
- Escalation Rate: 12.3%

Winner: Variant B (+52% improvement)
Statistical Significance: p < 0.05 âœ…
```

## ğŸ® Customer Signup Testing

### To Test Real Customer Flow:

1. **Create Test Customer Account**:
   - Sign up with different email
   - Set up widget on test website
   - Configure personality settings

2. **Simulate Customer Interactions**:
   - Visit test website as anonymous user
   - Start chat conversations
   - Provide feedback/ratings
   - Complete conversion actions

3. **Monitor Results**:
   - Check analytics dashboard
   - Review A/B test metrics
   - Analyze conversation quality

## ğŸš€ Quick Start Testing Checklist

- [ ] Apply database schema (`sql/final_safe_tables.sql`)
- [ ] Test URL Scanner with `www.weddingwire.com`
- [ ] Create A/B test in Playground
- [ ] Generate sample data (100 conversations)
- [ ] Review statistical analysis results
- [ ] Fix OpenAI API connection for real testing
- [ ] Set up Multi-Channel webhooks if needed
- [ ] Create test customer account for end-to-end testing

## ğŸ’¡ No Knowledge Base Scenario

If customer hasn't scanned any websites yet:

1. **Fallback Responses**: AI uses default company info
2. **Generic Knowledge**: Basic support responses
3. **Escalation Trigger**: "I don't have specific information about pricing. Let me connect you with someone who can help."
4. **Recommendation**: System suggests uploading knowledge base

This actually makes A/B testing more valuable - you're testing pure personality differences without knowledge interference!

---

## ğŸ¯ Bottom Line

A/B testing measures **which AI personality converts better** by tracking real customer interaction metrics. The playground generates realistic sample data to show you exactly what those results would look like. For production testing, you need real customers interacting with embedded widgets.